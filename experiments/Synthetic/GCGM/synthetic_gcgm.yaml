MODEL_NAME: gcgm_bias
DATASET_NAME: synthetic

DATASET_FULL_NAME: MixedSynthetic

MODULE: models.GCGM.model

BACKBONE: NoBackbone

CONFIG_NAME: synthetic_gcgm
CONFIG_DESCRIPTION: tri graphs for both src and tgt; with projection head; single gpu; 4 workers;

BATCH_SIZE: 32
DATALOADER_NUM: 4
FP16: False

RANDOM_SEED: 3

# available GPU ids
GPUS:
  - 0

PROBLEM:
  TYPE: GCL
  RESCALE:  # rescaled image size
    - 1
    - 1
  SRC_OUTLIER: True
  TGT_OUTLIER: True
  SSL: True
  FILTER: unfiltered

# Graph construction settings
GRAPH:
  SRC_GRAPH_CONSTRUCT: tri
  TGT_GRAPH_CONSTRUCT: tri
  SYM_ADJACENCY: True

# Synthetic dataset settings
SYNTHETIC:
  MIXED_DATA_NUM: 10
  DIM: 2  # synthetic feature dimension
  TRAIN_NUM: 200  # number of training samples
  TEST_NUM: 100  # number of testing samples
  KPT_NUM: 10  # keypoint num
  OUT_NUM: 2
  FEAT_GT_UNIFORM: 1.  # feature vector ~ uniform(-X, X)
  FEAT_NOISE_STD: 1.5  # feature noise ~ N(0, X^2)
  POS_GT_UNIFORM: 1.  # keypoint position ~ uniform(0, X)
  POS_AFFINE_DXY: 0. # 50.  # t_x, t_y ~ uniform(-X, X)
  POS_AFFINE_S_LOW: .8 # 0.8  # s ~ uniform(S_LOW, S_HIGH) \delta_s = 0.2
  POS_AFFINE_S_HIGH: 1.2 # 1.2
  POS_AFFINE_DTHETA: 0. #60.  # theta ~ uniform(-X, X)
  POS_NOISE_STD: 0.02  # position noise ~ N(0, X^2) \sigma_n

# Training settings
TRAIN:
  # start, end epochs
  START_EPOCH: 0
  NUM_EPOCHS: 10

  LOSS_FUNC:
    - nodeagreement
    - perm

  # * optimizer
  OPTIMIZER: Adam
  WEIGHT_DECAY: 1.e-2

  # * backbone
  FINETUNE_BACKBONE: False
  SEPARATE_BACKBONE_LR: True
  BACKBONE_LR: 1.e-5

  # * encoder
  FINETUNE_ENCODER: True
  SEPARATE_ENCODER_LR: False
  ENCODER_LR: 1.e-4

  # * lr
  LR: 1.e-5
  MOMENTUM: 0.9
  LR_DECAY: 0.5
  LR_STEP:  # (in epochs)
    - 

  EPOCH_ITERS: 500  # iterations per epoch

  CLASS: none

  # * validation and early stopping
  SPLIT: 0.8
  PATIENCE: 1
  DELTA: 0.001

  SAMPLES:
    - 3200 # 8000
    - 1600

# Evaluation settings
EVAL:
  EPOCH: 30  # epoch to be tested
  SAMPLES: 100  # number of tested pairs for each class

# model parameters
GCGM:
  EDGE_FEATURE: geo
  # node feature size before the affinity layer
  FEATURE_CHANNEL: 2 # Synthetic.DIM
  SK_ITER_NUM: 20
  SK_EPSILON: 1.0e-10
  SK_TAU: 0.05
  GNN_FEAT:
    - 16
    - 16
    - 16
  GNN_LAYER: 3
  GAUSSIAN_SIGMA: 5.e-7
  SK_EMB: 1
  FIRST_ORDER: True # False
  EDGE_EMB: False
  
  # encoder
  ENCODER_STRUCTURE: Pre
  PROJECTION_STRUCTURE: SimCLR
  # * IN_CHANNELS = FEATURE_CHANNEL
  IN_CHANNELS: 2
  INTER_CHANNELS: 16
  OUT_CHANNELS: 8
  ACTIVATION: leaky_relu
  SKIP: True
  PROJECT: FALSE
  K: 1
  AGGR: mean
  GLOBAL_READOUT: max
  # * model hyperparameters
  BASE_MODEL: SAGEConv
  DROPOUT: 0.2

  # * node agreement loss
  # temperature parameter
  TAU: 0.07
  # projection head `math: g(\cdot)`
  PROJECTION_HEAD: True
  PROJECTION_CHANNELS: 4
  BIAS: True

  USE_GLOBAL: False
  C_LOSS_RATE: 1

AUGMENTATION:
  MIXUP: 
    - "random, 128, (0.1, 0.9)"
  EDGES_INSERTION: 
    - "random, 128, (0.1, 0.9)"
  EDGE_REMOVING: 
    - "random, 128, (0.1, 0.9)"
  NODES_INSERTION: 
    - "random, 128, (0.1, 0.9), (2, 5), (mean, sum), (1, 5)"
  NODES_DELETION: 
    - "random, 128, (0.1, 0.9)"
  NODES_MODIFICATION:
    - "random, 128, (0.1, 0.5), (2, 5), (mean, sum), (1, 5)"
  NODE_FEATURE_MASKING: 
    - "random, 128, (0.1, 0.9)"
  RANDOM_AMPLITUDE_SCALING_SINGLE:
    - "random, 128, (0.2, 0.8), (1.2, 1.8)"
  RANDOM_AMPLITUDE_SCALING_MULTIVARIATE:
    - "random, 128, (0.2, 0.8), (1.2, 1.8)"
  
# * hyperpaprameter for boosting
BiAS:
  SAMPLE: 64
  PAIRS: 128
  LAMBDA: 0.80
  ALPHA: 3.00
  REWEIGHT: False
  PATIENCE: 1
  DECREASE_FACTOR: 0.5