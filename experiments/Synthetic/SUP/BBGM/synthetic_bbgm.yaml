MODEL_NAME: bbgm
DATASET_NAME: synthetic

DATASET_FULL_NAME: MixedSynthetic

MODULE: models.BBGM.model

BACKBONE: NoBackbone

CONFIG_NAME: synthetic_bbgm
CONFIG_DESCRIPTION: no backbone

BATCH_SIZE: 8
DATALOADER_NUM: 4

RANDOM_SEED: 123

# available GPU ids
GPUS:
  - 0

PROBLEM:
  TYPE: 2GM
  RESCALE:  # rescaled image size
    - 256
    - 256
  SRC_OUTLIER: True
  TGT_OUTLIER: True
  FILTER: unfiltered

SSL:
  USE_GLOBAL: False

# Graph construction settings
GRAPH:
  SRC_GRAPH_CONSTRUCT: tri
  TGT_GRAPH_CONSTRUCT: tri
  SYM_ADJACENCY: True

# Synthetic dataset settings
SYNTHETIC:
  MIXED_DATA_NUM: 10
  DIM: 2  # synthetic feature dimension
  TRAIN_NUM: 200  # number of training samples
  TEST_NUM: 100  # number of testing samples
  KPT_NUM: 10  # keypoint num
  OUT_NUM: 2
  FEAT_GT_UNIFORM: 1.  # feature vector ~ uniform(-X, X)
  FEAT_NOISE_STD: 1.5  # feature noise ~ N(0, X^2)
  POS_GT_UNIFORM: 1.  # keypoint position ~ uniform(0, X)
  POS_AFFINE_DXY: 0. #50.  # t_x, t_y ~ uniform(-X, X)
  POS_AFFINE_S_LOW: .8 #0.8  # s ~ uniform(S_LOW, S_HIGH)
  POS_AFFINE_S_HIGH: 1.2 #1.2
  POS_AFFINE_DTHETA: 0. #60.  # theta ~ uniform(-X, X)
  POS_NOISE_STD: 0.02  # position noise ~ N(0, X^2)

# Training settings
TRAIN:
  # start, end epochs
  START_EPOCH: 0
  NUM_EPOCHS: 10

  LOSS_FUNC: 
    - hamming

  # learning rate
  LR: 1.0e-2
  MOMENTUM: 0.9
  LR_DECAY: 0.1
  LR_STEP:  # (in epochs)
    #- 3
    - 5

  EPOCH_ITERS: 500  # iterations per epoch

  CLASS: none

  # * validation and early stopping
  SPLIT: 0.8
  DELTA: 0.001
  PATIENCE: 1

  SAMPLES:
    - 3200
    - 1600

# Evaluation settings
EVAL:
  EPOCH: 30  # epoch to be tested
  SAMPLES: 100  # number of tested pairs for each class

# model parameters
BBGM:
  SOLVER_NAME: LPMP
  LAMBDA_VAL: 80.0
  SOLVER_PARAMS:
    timeout: 1000
    primalComputationInterval: 10
    maxIter: 100
  # * new hyperparameters
  EDGE_FEATURE: geo
  FEATURE_CHANNEL: 2
  GLOBAL_READOUT: mean
  GAUSSIAN_SIGMA: 5.e-7